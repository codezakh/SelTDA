image_folder: /net/acadia10a/data/zkhan/coco2017/unlabeled2017
output_folder: /net/acadia10a/data/zkhan/vqav2_annotations/
annotations: null
pretrained: /net/acadia10a/data/zkhan/mithril/blip_vqg_2/checkpoint_04.pth
output_annotations_name: coco_generated_qa.json
image_size: 384
max_length: 30
min_length: 5
num_beams: 3
prompt: 'Question: '
torch_home: /net/acadia10b/data/zkhan/torch_home
vit: base
questions_per_image: 1
multimodal_encoder_decoder_config: /home/mai/zkhan/BLIP/configs/med_config.json
batch_size: 64
truncate_to: null
num_workers: 4
top_p: 0.9
vqa_dataset_origin: 'vqa'
dry_run: false
shuffle: false

parse_rationale: false
truncate_to_strict: null