[![Conference](https://img.shields.io/badge/CVPR-2023-blue)]()
# SelTDA
This repository will hold the official code of SelTDA, the self-training framework introduced in our CVPR 2023 paper "Q: How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks? A: Self-Train on Unlabeled Images!".


![seltda_teaser](https://user-images.githubusercontent.com/4918041/225918833-7d744775-260a-4bc3-a642-7279531b5b07.png)
